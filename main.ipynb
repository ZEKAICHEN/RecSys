{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchfm.dataset.avazu import AvazuDataset\n",
    "from torchfm.dataset.criteo import CriteoDataset\n",
    "from torchfm.dataset.movielens import MovieLens1MDataset, MovieLens20MDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchfm.model.mhafm import MultiheadAttentionalFactorizationMachineModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(name, path):\n",
    "    if name == 'movielens1M':\n",
    "        return MovieLens1MDataset(path)\n",
    "    elif name == 'movielens20M':\n",
    "        return MovieLens20MDataset(path)\n",
    "    elif name == 'criteo':\n",
    "        return CriteoDataset(path)\n",
    "    elif name == 'avazu':\n",
    "        return AvazuDataset(path)\n",
    "    else:\n",
    "        raise ValueError('unknown dataset name: ' + name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_name, dataset_path = 'avazu', './data/avazu/train.csv'\n",
    "dataset = get_dataset(dataset_name, dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4096\n",
    "\n",
    "train_length = int(len(dataset) * 0.8)\n",
    "valid_length = int(len(dataset) * 0.1)\n",
    "test_length = len(dataset) - train_length - valid_length\n",
    "# test_length = int(len(dataset) * 0.01)\n",
    "train_dataset, valid_dataset, test_dataset = torch.utils.data.random_split(\n",
    "    dataset, (train_length, valid_length, test_length))\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=8)\n",
    "valid_data_loader = DataLoader(valid_dataset, batch_size=batch_size, num_workers=8)\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fields, target in train_data_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "field_dims = dataset.field_dims\n",
    "num_fields = len(field_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4096, 39])\n"
     ]
    }
   ],
   "source": [
    "print(fields.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiheadAttentionalFactorizationMachineModel(field_dims, embed_dim=16, \n",
    "                                                      num_heads=4, ffn_embed_dim=64,\n",
    "                                                      num_layers=3, mlp_dims=(16, 16), dropout=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2048])\n"
     ]
    }
   ],
   "source": [
    "print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (torch.triu(torch.ones(6, 6)) == 1)\n",
    "mask = mask.float().masked_fill(mask == 0, float(0.0)).masked_fill(mask == 1, float('-inf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., -inf]])\n"
     ]
    }
   ],
   "source": [
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchfm.layer import FeaturesEmbedding\n",
    "\n",
    "embedding = FeaturesEmbedding(field_dims, 16)\n",
    "x = embedding(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "row, col = list(), list()\n",
    "for i in range(num_fields - 1):\n",
    "    for j in range(i + 1, num_fields):\n",
    "        row.append(i), col.append(j)\n",
    "p, q = x[:, row], x[:, col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2048, 231, 16])\n"
     ]
    }
   ],
   "source": [
    "print(p.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
